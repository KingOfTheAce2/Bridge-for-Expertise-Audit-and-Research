[package]
name = "bear-llm-ai"
version = "0.0.1"
edition = "2021"

[dependencies]
tauri = { version = "2", features = [] }
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
anyhow = "1.0"
chrono = "0.4"

# Database dependencies
sea-orm = { version = "0.12", features = ["sqlx-sqlite", "runtime-tokio-native-tls", "macros"] }
sea-orm-migration = "0.12"
sqlx = { version = "0.7", features = ["sqlite", "runtime-tokio"] }
tokio = { version = "1.36", features = ["full"] }

# Optional: logging for debugging
log = "0.4"
env_logger = "0.10"

# AI and Model Management dependencies (Phase 3)
# Candle with GPU support - conditionally enabled based on platform
candle-core = "0.7"
candle-nn = "0.7"
candle-transformers = "0.7"
hf-hub = "0.3"
tokenizers = "0.15"
reqwest = { version = "0.12", features = ["stream", "json"] }
sha2 = "0.10"
hex = "0.4"
futures = "0.3"
indicatif = "0.17"
dirs = "5.0"
safetensors = "0.4"
memmap2 = "0.9"

# Force compatible versions to resolve dependency conflicts
half = "=2.4.1"  # Pin to version compatible with rand 0.8

# PII Detection dependencies (Phase 4)
regex = "1.10"

# Prompt Library dependencies (Phase 5)
serde_yaml = "0.9"
walkdir = "2.4"
uuid = { version = "1.6", features = ["v4", "serde"] }

# Local crates
entity = { path = "entity" }
migration = { path = "migration" }

[build-dependencies]
tauri-build = { version = "2", features = [] }

[dev-dependencies]
tempfile = "3.10"

[features]
default = []
# GPU acceleration features (opt-in)
cuda = ["candle-core/cuda", "candle-nn/cuda", "candle-transformers/cuda"]
metal = ["candle-core/metal", "candle-nn/metal", "candle-transformers/metal"]
accelerate = ["candle-core/accelerate", "candle-nn/accelerate", "candle-transformers/accelerate"]
